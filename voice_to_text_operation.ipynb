{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wavio as wv\n",
    "# from scipy.io.wavfile import write\n",
    "# import sounddevice as sd\n",
    "# # Sampling frequency\n",
    "# freq = 44100\n",
    "\n",
    "# # Recording duration\n",
    "# duration = 5\n",
    "# # Start recorder with the given values of \n",
    "# # duration and sample frequency\n",
    "# recording = sd.rec(int(duration * freq), samplerate=freq, channels=1)\n",
    "\n",
    "# # Record audio for the given number of seconds\n",
    "# sd.wait()\n",
    "# # This will convert the NumPy array to an audio\n",
    "# # file with the given sampling frequency\n",
    "# write(\"recording0.wav\", freq, recording)\n",
    "# # Convert the NumPy array to audio file\n",
    "# wv.write(\"recording1.wav\", recording, freq, sampwidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/usama/anaconda3/lib/python3.10/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/usama/Downloads/voice/test3.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train to meet another test\n"
     ]
    }
   ],
   "source": [
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(path):\n",
    "    # use the audio file as the audio source\n",
    "    with sr.AudioFile(path) as source:\n",
    "        audio_listened = r.record(source)\n",
    "        # try converting it to text\n",
    "        text = r.recognize_google(audio_listened)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_large_audio_transcription_on_silence(path):\n",
    "    \"\"\"Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_file(path)  \n",
    "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        try:\n",
    "            text = transcribe_audio(chunk_filename)\n",
    "        except sr.UnknownValueError as e:\n",
    "            print(\"Error:\", str(e))\n",
    "        else:\n",
    "            text = f\"{text.capitalize()}. \"\n",
    "            print(chunk_filename, \":\", text)\n",
    "            whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks/chunk1.wav : Train to make another test. \n",
      "audio-chunks/chunk1.wav : Train to make another test. \n",
      "\n",
      "Full text: Train to make another test. \n"
     ]
    }
   ],
   "source": [
    "path = \"test3.wav\"\n",
    "text = get_large_audio_transcription_on_silence(path)\n",
    "print(\"\\nFull text:\", get_large_audio_transcription_on_silence(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download([\"names\", \"stopwords\", \"state_union\", \"twitter_samples\", \"movie_reviews\", \"averaged_perceptron_tagger\", \"vader_lexicon\", \"punkt\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.314, 'neu': 0.286, 'pos': 0.4, 'compound': 0.2263}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i love you you ugly thing\"\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
